# Copyright Â© 2022 Cask Data, Inc.
#  Licensed under the Apache License, Version 2.0 (the "License"); you may not
#  use this file except in compliance with the License. You may obtain a copy of
#  the License at
#  http://www.apache.org/licenses/LICENSE-2.0
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#  License for the specific language governing permissions and limitations under
#  the License.


#  This workflow will automate the release of artifacts from this repository to CDF Hub GCS Buckets
name: Hub Release Automation

on:
  push:    # Automated trigger on deploy branch
    branches:
    - deploy
  workflow_dispatch:    # Manual trigger event to execute workflow

concurrency:
  group: automation    # In-order execution by limiting to only 1 workflow run at a time

env:
  CENTRAL_GCS_BUCKET_PREFIX: 'hub-cdap-io/v2'

jobs:

  setup-build-and-list-missing-artifacts:    # Job to build packages.json file, find and list missing files
    runs-on: cdapio-hub-k8-runner    # Self hosted runner on GKE cluster

    steps:

    - name: Repository Checkout    # Action to access file structure of repository in runner
      uses: actions/checkout@v2.3.4

    - name: Run Script to Build packages.json    # Step to execute build.py script that performs build operations of this job
      run: python3 ./.github/scripts/build.py

    - name: Store packages.json as Artifact    # Action to upload packages.json as an artifact for further use
      uses: actions/upload-artifact@v3
      with:
        name: packages.json
        path: ./packages.json

    - name: Run Script to List Missing Artifact Files    # Step to execute list.py script that performs find and list operations of this job
      run: python3 ./.github/scripts/list.py

    - name: Setting Output    # Step to set resultant list as output of job
      id: set-matrix
      run: echo "::set-output name=matrix::${output}"

    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}    # JSON output containing contents of strategy matrix of next job

  fetch-missing-artifacts:    # Job to fetch each missing file individually in parallel
    needs: setup-build-and-list-missing-artifacts
    if: ${{ needs.setup-build-and-list-missing-artifacts.outputs.matrix != '[]' && needs.setup-build-and-list-missing-artifacts.outputs.matrix != '' && success() }}    # Skip job if no file to be fetched. Execute job sequentially after completion of previous jobs without failure
    runs-on: cdapio-hub-k8-runner

    strategy:
      matrix:
        artifact: ${{ fromJSON(needs.setup-build-and-list-missing-artifacts.outputs.matrix) }}

    env:
      ID: ${{ matrix.artifact.repo.id }}
      EXTENSION: ${{ matrix.artifact.repo.file_type }}
      DIR: ${{ matrix.artifact.artifactDir }}
      FILEPATH: ${{ matrix.artifact.path }}
      FILENAME: ${{ matrix.artifact.artifact }}

    steps:

    - name: Creating Working Directory    # Step to create a temporary working directory
      run: mkdir artifact

    - name: Sync with GCS    # Step to sync GCS bucket directory that is expected to contain missing file with working directory
      run: gsutil rsync gs://hub-cdap-io/v2/$DIR artifact/

    - name: Fetching Missing Files    # Step to find and fetch the missing file
      run: |
        echo "Fetching: ${FILEPATH}"
        if [ -f "artifact/${FILENAME}" ]; then
          echo "${FILENAME} : Found in GCS Bucket"
        else
          echo "${FILENAME} : Not found in GCS Bucket, Fetching from Maven Central"
          mvn org.apache.maven.plugins:maven-dependency-plugin:2.8:copy -Dartifact=${ID}:${VERSION}:${EXTENSION} -DoutputDirectory=./artifact/
        fi

    - name: Upload Files    # Action to upload the fetched missing file as an artifact
      uses: actions/upload-artifact@v3
      with:
        name: ${{ matrix.artifact.artifact }}
        path: ${{ matrix.artifact.target_path }}

  merge-missing-artifacts:    # Job to place all artifacts in appropriate location, and push to GCS buckets
    needs: fetch-missing-artifacts
    if: success()
    runs-on: cdapio-hub-k8-runner

    steps:

    - name: Repository Checkout    # Action to access file structure of repository in runner
      uses: actions/checkout@v2.3.4

    - name: Download Artifact    # Action to download all the fetched missing files to a temporary artifacts directory
      uses: actions/download-artifact@v3
      with:
        path: artifacts/

    - name: Run Script to Merge Fetched Missing Files    # Step to execute merge.py script that performs operations of this job
      run: python3 ./.github/scripts/merge.py

    - name: Syncing Central GCS Bucket    # Step to sync central GCS bucket with updated artifacts, along with cleanup of bucket
      uses: nick-fields/retry@e88a9994b039653512d697de1bce46b00bfe11b5    # Retrying upto 3 times if operations fails due to network error
      with:
        timeout_seconds: 600
        max_attempts: 3
        retry_on: any
        on_retry_command: echo "The upload to central bucket failed in this attempt, retrying...."
        command: python3 ./.github/scripts/sync.py

    - name: Setting GCS Bucket List Output    # Step to set resultant list as output of job
      id: set-gcs-buckets
      run: echo "::set-output name=buckets::${buckets}"

    outputs:
      matrix: ${{ steps.set-gcs-buckets.outputs.buckets }}    # JSON output containing contents of strategy matrix of next job


  sync-regional-buckets:    # Job to sync all regional GCS buckets with central GCS bucket, in parallel
    runs-on: cdapio-hub-k8-runner
    needs: merge-missing-artifacts
    if: success()

    strategy:
      matrix:
        loc: ${{ fromJSON(needs.merge-missing-artifacts.outputs.matrix) }}

    steps:

    - name: Syncing buckets, max 3 retries    # Action to sync bucket, and retry upto 3 times if failed
      uses: nick-fields/retry@e88a9994b039653512d697de1bce46b00bfe11b5
      with:
        timeout_seconds: 600
        max_attempts: 3
        retry_on: any
        on_retry_command: echo "The upload to regional bucket has failed in this attempt, retrying ..."
        command: |
          # TODO : remove -n after verification.
          gsutil -m rsync -d -c -r -n ${{ matrix.loc.central_address }} ${{ matrix.loc.regional_address }}