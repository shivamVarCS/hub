{
  "parents": [
    "system:cdap-data-pipeline[6.0.0-SNAPSHOT,7.0.0-SNAPSHOT)",
    "system:cdap-data-streams[6.0.0-SNAPSHOT,7.0.0-SNAPSHOT)"
  ],
  "properties": {
    "widgets.ORCDynamicPartitionedDataset-batchsink": "{\"metadata\":{\"spec-version\":\"1.3\"},\"configuration-groups\":[{\"label\":\"ORC Dynamic Partitioned Dataset\",\"properties\":[{\"widget-type\":\"dataset-selector\",\"label\":\"Dataset Name\",\"name\":\"name\"},{\"widget-type\":\"textbox\",\"label\":\"Dataset Base Path\",\"name\":\"basePath\",\"placeholder\":\"E.g. /tmp/folder/\"},{\"widget-type\":\"csv\",\"label\":\"Partition Field Names\",\"name\":\"fieldNames\"},{\"widget-type\":\"select\",\"label\":\"Compression Codec\",\"name\":\"compressionCodec\",\"widget-attributes\":{\"values\":[\"None\",\"Snappy\",\"ZLIB\"],\"default\":\"None\"}},{\"widget-type\":\"select\",\"label\":\"Append to Existing Partition\",\"name\":\"appendToPartition\",\"widget-attributes\":{\"values\":[\"Yes\",\"No\"],\"default\":\"No\"}},{\"widget-type\":\"textbox\",\"label\":\"Compression Chunk Size\",\"name\":\"compressionChunkSize\"},{\"widget-type\":\"textbox\",\"label\":\"Bytes per stripe\",\"name\":\"stripeSize\"},{\"widget-type\":\"textbox\",\"label\":\"Rows between index entries\",\"name\":\"indexStride\"},{\"widget-type\":\"select\",\"label\":\"Create inline indices\",\"name\":\"createIndex\",\"widget-attributes\":{\"values\":[\"True\",\"False\"],\"default\":\"True\"}}]}],\"outputs\":[{\"name\":\"schema\",\"widget-type\":\"schema\",\"widget-attributes\":{\"schema-types\":[\"boolean\",\"int\",\"long\",\"float\",\"double\",\"string\"],\"schema-default-type\":\"string\"}}],\"jump-config\":{\"datasets\":[{\"ref-property-name\":\"name\"}]}}",
    "widgets.AvroDynamicPartitionedDataset-batchsink": "{\"metadata\":{\"spec-version\":\"1.3\"},\"configuration-groups\":[{\"label\":\"Avro Dynamic Partitioned Dataset\",\"properties\":[{\"widget-type\":\"dataset-selector\",\"label\":\"Dataset Name\",\"name\":\"name\"},{\"widget-type\":\"textbox\",\"label\":\"Dataset Base Path\",\"name\":\"basePath\",\"placeholder\":\"E.g. /tmp/folder/\"},{\"widget-type\":\"csv\",\"label\":\"Partition Field Names\",\"name\":\"fieldNames\"},{\"widget-type\":\"select\",\"label\":\"Compression Codec\",\"name\":\"compressionCodec\",\"widget-attributes\":{\"values\":[\"None\",\"Snappy\",\"Deflate\"],\"default\":\"None\"}},{\"widget-type\":\"select\",\"label\":\"Append to Existing Partition\",\"name\":\"appendToPartition\",\"widget-attributes\":{\"values\":[\"Yes\",\"No\"],\"default\":\"No\"}}]}],\"outputs\":[{\"name\":\"schema\",\"widget-type\":\"schema\",\"widget-attributes\":{\"schema-types\":[\"boolean\",\"int\",\"long\",\"float\",\"double\",\"string\"],\"schema-default-type\":\"string\"}}],\"jump-config\":{\"datasets\":[{\"ref-property-name\":\"name\"}]}}",
    "widgets.ParquetDynamicPartitionedDataset-batchsink": "{\"metadata\":{\"spec-version\":\"1.3\"},\"configuration-groups\":[{\"label\":\"Parquet Dynamic Partitioned Fileset\",\"properties\":[{\"widget-type\":\"dataset-selector\",\"label\":\"Dataset Name\",\"name\":\"name\"},{\"widget-type\":\"textbox\",\"label\":\"Dataset Base Path\",\"name\":\"basePath\",\"placeholder\":\"E.g. /tmp/folder/\"},{\"widget-type\":\"csv\",\"label\":\"Partition Field Names\",\"name\":\"fieldNames\"},{\"widget-type\":\"select\",\"label\":\"Compression Codec\",\"name\":\"compressionCodec\",\"widget-attributes\":{\"values\":[\"None\",\"Snappy\",\"GZip\",\"LZO\"],\"default\":\"None\"}},{\"widget-type\":\"select\",\"label\":\"Append to Existing Partition\",\"name\":\"appendToPartition\",\"widget-attributes\":{\"values\":[\"Yes\",\"No\"],\"default\":\"No\"}}]}],\"outputs\":[{\"name\":\"schema\",\"widget-type\":\"schema\",\"widget-attributes\":{\"schema-types\":[\"boolean\",\"int\",\"long\",\"float\",\"double\",\"string\"],\"schema-default-type\":\"string\"}}],\"jump-config\":{\"datasets\":[{\"ref-property-name\":\"name\"}]}}",
    "doc.ParquetDynamicPartitionedDataset-batchsink": "# Parquet Dynamic Partitioned Dataset Batch Sink\n\n\nDescription\n-----------\nSink for a ``PartitionedDataset`` that writes data in Parquet format\nand leverages one or more record field values for creating partitions.\nAll data for the run will be written to a partition based on the\nspecified fields and their value.\n\n\nUse Case\n--------\nThis sink is used whenever you want to write to a ``PartitionedFileSet`` in Parquet format\nusing a value from the record as a partition. For example, you might want to load historical\ndata from a database and partition the dataset on the original creation date of the data.\n\n\nProperties\n----------\n| Configuration | Required | Default | Description |\n| :------------ | :------: | :------ | :---------- |\n| **Dataset Name** | **Y** | None| Name of the ``PartitionedFileSet`` to which records are written. If it doesn't exist, it will be created. |\n| **Schema** | **Y** | None | The Avro schema of the record being written to the sink as a JSON Object. |\n| **Partition Field Names** | **Y** | None | One or more fields that will be used to partition the dataset. |\n| **Dataset Base Path** | **N** | [Namespace]/data/[Dataset name] | Base path for the ``PartitionedFileSet``. Defaults to the name of the dataset. |\n| **Compression Codec** | **N** | None | Optional parameter to determine the compression codec to use on the resulting data. Valid values are None, Snappy, GZip, and LZO. |\n| **Append to Existing Partition** | **N** | No | Allow appending to existing partitions, by default this capability is disabled.|\n\nExample\n-------\n\nFor example, suppose the sink receives input records from customers and purchases:\n\n\n    +==================================================================================================+\n    | id | first_name | last_name |  street_address      |   city    | state | zipcode | purchase_date |  \n    +==================================================================================================+\n    | 1  | Douglas    | Williams  | 1, Vista Montana     | San Jose  | CA    | 95134   | 2009-01-02    |\n    | 2  | David      | Johnson   | 3, Baypointe Parkway | Houston   | TX    | 78970   | 2009-01-01    |\n    | 3  | Hugh       | Jackman   | 5, Cool Way          | Manhattan | NY    | 67263   | 2009-01-01    |\n    | 4  | Walter     | White     | 3828, Piermont Dr    | Orlando   | FL    | 73498   | 2009-01-03    |\n    | 5  | Frank      | Underwood | 1609 Far St.         | San Diego | CA    | 29770   | 2009-01-03    |\n    | 6  | Serena     | Woods     | 123 Far St.          | Las Vegas | Nv    | 45334   | 2009-01-01    |\n    +==================================================================================================+\n\nIf we choose ``purchase_date`` as a partition column field, the sink will create a ``PartitionedDataset`` and populate \nthe partitions as follows:\n\n\n    +==================================================================================================+\n    | id | first_name | last_name |  street_address      |   city    | state | zipcode | purchase_date |  \n    +==================================================================================================+\n    | 2  | David      | Johnson   | 3, Baypointe Parkway | Houston   | TX    | 78970   | 2009-01-01    |\n    | 3  | Hugh       | Jackman   | 5, Cool Way          | Manhattan | NY    | 67263   | 2009-01-01    |\n    | 6  | Serena     | Woods     | 123 Far St.          | Las Vegas | Nv    | 45334   | 2009-01-01    |\n    +==================================================================================================+\n\n    +==================================================================================================+\n    | id | first_name | last_name |  street_address      |   city    | state | zipcode | purchase_date |  \n    +==================================================================================================+\n    | 1  | Douglas    | Williams  | 1, Vista Montana     | San Jose  | CA    | 95134   | 2009-01-02    |\n    +==================================================================================================+\n\n    +==================================================================================================+\n    | id | first_name | last_name |  street_address      |   city    | state | zipcode | purchase_date |  \n    +==================================================================================================+\n    | 4  | Walter     | White     | 3828, Piermont Dr    | Orlando   | FL    | 73498   | 2009-01-03    |\n    | 5  | Frank      | Underwood | 1609 Far St.         | San Diego | CA    | 29770   | 2009-01-03    |\n    +==================================================================================================+\n    \n",
    "doc.README": "Dynamic Partitioner Plugins\n===========================\n\n<a href=\"https://cdap-users.herokuapp.com/\"><img alt=\"Join CDAP community\" src=\"https://cdap-users.herokuapp.com/badge.svg?t=1\"/></a> [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0) <img  alt=\"Not Available in Cask Market\" src=\"https://cdap-users.herokuapp.com/assets/cm-notavailable.svg\"/>\n\nCDAP Plugins for Sinks that allow you to specify a list of fields, and leverage the values as partitions in the dataset.\n\nBuild\n-----\nTo build this plugin:\n\n```\n   mvn clean package\n```    \n\nThe build will create a .jar and .json file under the ``target`` directory.\nThese files can be used to deploy your plugins.\n\nDeployment\n----------\nYou can deploy your plugins using the CDAP CLI:\n\n    > load artifact <target/plugin.jar> config-file <target/plugin.json>\n\nFor example, if your artifact is named 'kudu-sink-1.0.0':\n\n    > load artifact target/dynamic-partitioner-1.0.0.jar config-file target/dynamic-partitioner-1.0.0.json\n    \n## Mailing Lists\n\nCDAP User Group and Development Discussions:\n\n* `cdap-user@googlegroups.com <https://groups.google.com/d/forum/cdap-user>`\n\nThe *cdap-user* mailing list is primarily for users using the product to develop\napplications or building plugins for appplications. You can expect questions from \nusers, release announcements, and any other discussions that we think will be helpful \nto the users.\n\n## IRC Channel\n\nCDAP IRC Channel: #cdap on irc.freenode.net\n\n\n## License and Trademarks\n\nCopyright Â© 2016-2017 Cask Data, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\nin compliance with the License. You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the \nLicense is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, \neither express or implied. See the License for the specific language governing permissions \nand limitations under the License.\n\nCask is a trademark of Cask Data, Inc. All rights reserved.\n\nApache, Apache HBase, and HBase are trademarks of The Apache Software Foundation. Used with\npermission. No endorsement by The Apache Software Foundation is implied by the use of these marks.    \n",
    "doc.AvroDynamicPartitionedDataset-batchsink": "# Avro Dynamic Partitioned Dataset Batch Sink\n\n\nDescription\n-----------\nSink for a ``PartitionedDataset`` that writes data in Avro format\nand leverages one or more record field values for creating partitions.\nAll data for the run will be written to a partition based on the\nspecified fields and their value.\n\n\nUse Case\n--------\nThis sink is used whenever you want to write to a ``PartitionedFileSet`` in Avro format\nusing a value from the record as a partition. For example, you might want to load historical\ndata from a database and partition the dataset on the original creation date of the data.\n\n\nProperties\n----------\n| Configuration | Required | Default | Description |\n| :------------ | :------: | :------ | :---------- |\n| **Dataset name** | **Y** | None| Name of the ``PartitionedFileSet`` to which records are written. If it doesn't exist, it will be created. |\n| **Schema** | **Y** | None | The schema of the record being written to the sink as a JSON Object. |\n| **Partition Field Names** | **Y** | None | One or more fields that will be used to partition the dataset. |\n| **Dataset Base Path** | **N** | [Namepsace]/data/[Dataset name] | Base path for the ``PartitionedFileSet``. Defaults to the name of the dataset. |\n| **Compression Codec** | **N** | None | Optional parameter to determine the compression codec to use on the resulting data. Valid values are None, Snappy, and GZip. |\n| **Append to Existing Partition** | **N** | No | Allow appending to existing partitions, by default this capability is disabled.|\n\nExample\n-------\n\nFor example, suppose the sink receives input records from customers and purchases:\n\n\n    +==================================================================================================+\n    | id | first_name | last_name |  street_address      |   city    | state | zipcode | purchase_date |  \n    +==================================================================================================+\n    | 1  | Douglas    | Williams  | 1, Vista Montana     | San Jose  | CA    | 95134   | 2009-01-02    |\n    | 2  | David      | Johnson   | 3, Baypointe Parkway | Houston   | TX    | 78970   | 2009-01-01    |\n    | 3  | Hugh       | Jackman   | 5, Cool Way          | Manhattan | NY    | 67263   | 2009-01-01    |\n    | 4  | Walter     | White     | 3828, Piermont Dr    | Orlando   | FL    | 73498   | 2009-01-03    |\n    | 5  | Frank      | Underwood | 1609 Far St.         | San Diego | CA    | 29770   | 2009-01-03    |\n    | 6  | Serena     | Woods     | 123 Far St.          | Las Vegas | Nv    | 45334   | 2009-01-01    |\n    +==================================================================================================+\n\nIf we choose ``purchase_date`` as a partition column field, the sink will create a ``PartitionedDataset`` and populate \nthe partitions as follows:\n\n\n    +==================================================================================================+\n    | id | first_name | last_name |  street_address      |   city    | state | zipcode | purchase_date |  \n    +==================================================================================================+\n    | 2  | David      | Johnson   | 3, Baypointe Parkway | Houston   | TX    | 78970   | 2009-01-01    |\n    | 3  | Hugh       | Jackman   | 5, Cool Way          | Manhattan | NY    | 67263   | 2009-01-01    |\n    | 6  | Serena     | Woods     | 123 Far St.          | Las Vegas | Nv    | 45334   | 2009-01-01    |\n    +==================================================================================================+\n\n    +==================================================================================================+\n    | id | first_name | last_name |  street_address      |   city    | state | zipcode | purchase_date |  \n    +==================================================================================================+\n    | 1  | Douglas    | Williams  | 1, Vista Montana     | San Jose  | CA    | 95134   | 2009-01-02    |\n    +==================================================================================================+\n\n    +==================================================================================================+\n    | id | first_name | last_name |  street_address      |   city    | state | zipcode | purchase_date |  \n    +==================================================================================================+\n    | 4  | Walter     | White     | 3828, Piermont Dr    | Orlando   | FL    | 73498   | 2009-01-03    |\n    | 5  | Frank      | Underwood | 1609 Far St.         | San Diego | CA    | 29770   | 2009-01-03    |\n    +==================================================================================================+\n    \n",
    "doc.ORCDynamicPartitionedDataset-batchsink": "# ORC Dynamic Partitioned Dataset Batch Sink\n\n\nDescription\n-----------\nSink for a ``PartitionedFileSet`` that writes data in ORC format\nand leverages one or more record field values for creating partitions.\nAll data for the run will be written to a partition based on the\nspecified fields and their value.\n\n\nUse Case\n--------\nThis sink is used whenever you want to write to a ``PartitionedFileSet`` in ORC format\nusing a value from the record as a partition. For example, you might want to load historical\ndata from a database and partition the dataset on the original creation date of the data.\n\n\nProperties\n----------\n| Configuration | Required | Default | Description |\n| :------------ | :------: | :------ | :---------- |\n| **Dataset Name** | **Y** | None| Name of the ``PartitionedFileSet`` to which records are written. If it doesn't exist, it will be created. |\n| **Schema** | **Y** | None | The schema of the record being written to the sink as a JSON Object. |\n| **Partition Field Names** | **Y** | None | One or more fields that will be used to partition the dataset. |\n| **Dataset Base Path** | **N** | [Namespace]/data/[Dataset name] | Base path for the ``PartitionedFileSet``. Defaults to the name of the dataset. |\n| **Compression Codec** | **N** | None | Optional parameter to determine the compression codec to use on the resulting data. Valid values are None, Snappy, and zlib. |\n| **Append to Existing Partition** | **N** | No | Allow appending to existing partitions, by default this capability is disabled.|\n| **Compression Chunk Size** | **N** | None | Required if setting compressionCodec. Number of bytes in each compression chunk. |\n| **Bytes per stripe** | **N** | None | Required if Compression Codec is set. Number of bytes in each stripe. |\n| **Rows between index entries** | **N** | None | Required if Compression Codec is set. Number of rows between index entries (must be >= 1,000). |\n| **Create inline indices** | **N** | True | Required if Compression Codec is set. Whether to create inline indices. |\n\nExample\n-------\n\nFor example, suppose the sink receives input records from customers and purchases:\n\n\n    +==================================================================================================+\n    | id | first_name | last_name |  street_address      |   city    | state | zipcode | purchase_date |  \n    +==================================================================================================+\n    | 1  | Douglas    | Williams  | 1, Vista Montana     | San Jose  | CA    | 95134   | 2009-01-02    |\n    | 2  | David      | Johnson   | 3, Baypointe Parkway | Houston   | TX    | 78970   | 2009-01-01    |\n    | 3  | Hugh       | Jackman   | 5, Cool Way          | Manhattan | NY    | 67263   | 2009-01-01    |\n    | 4  | Walter     | White     | 3828, Piermont Dr    | Orlando   | FL    | 73498   | 2009-01-03    |\n    | 5  | Frank      | Underwood | 1609 Far St.         | San Diego | CA    | 29770   | 2009-01-03    |\n    | 6  | Serena     | Woods     | 123 Far St.          | Las Vegas | Nv    | 45334   | 2009-01-01    |\n    +==================================================================================================+\n\nIf we choose ``purchase_date`` as a partition column field, the sink will create a ``PartitionedDataset`` and populate \nthe partitions as follows:\n\n\n    +==================================================================================================+\n    | id | first_name | last_name |  street_address      |   city    | state | zipcode | purchase_date |  \n    +==================================================================================================+\n    | 2  | David      | Johnson   | 3, Baypointe Parkway | Houston   | TX    | 78970   | 2009-01-01    |\n    | 3  | Hugh       | Jackman   | 5, Cool Way          | Manhattan | NY    | 67263   | 2009-01-01    |\n    | 6  | Serena     | Woods     | 123 Far St.          | Las Vegas | Nv    | 45334   | 2009-01-01    |\n    +==================================================================================================+\n\n    +==================================================================================================+\n    | id | first_name | last_name |  street_address      |   city    | state | zipcode | purchase_date |  \n    +==================================================================================================+\n    | 1  | Douglas    | Williams  | 1, Vista Montana     | San Jose  | CA    | 95134   | 2009-01-02    |\n    +==================================================================================================+\n\n    +==================================================================================================+\n    | id | first_name | last_name |  street_address      |   city    | state | zipcode | purchase_date |  \n    +==================================================================================================+\n    | 4  | Walter     | White     | 3828, Piermont Dr    | Orlando   | FL    | 73498   | 2009-01-03    |\n    | 5  | Frank      | Underwood | 1609 Far St.         | San Diego | CA    | 29770   | 2009-01-03    |\n    +==================================================================================================+\n    \n"
  }
}